{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b8b42780",
   "metadata": {},
   "source": [
    "# Week 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a8a0eef",
   "metadata": {},
   "source": [
    "1.1.Image Formation. \n",
    "   \n",
    "1.1.1.geometry(了解). \n",
    "    Pinhole camera. \n",
    "    Projective geometry: perspective/affine. \n",
    "    Image distortions. \n",
    "\n",
    "1.1.2.Color module(描述). \n",
    "    RGB:defaule,缺点:correalted channels. \n",
    "    HSV:Intuitive,用在color selection/manipulation,缺点: confound channels. \n",
    "    YCbCr: compression/compute,用在jpeg. \n",
    "    L*a*b*: Perceptually uniform,用在ps. \n",
    "\n",
    "1.1.3.Digitisation:by spatial sampling. \n",
    "    Spatial resolutin: 分辨率依赖像素. \n",
    "    Quantisation(intensity): 2^8^. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "031216ae",
   "metadata": {},
   "source": [
    "2.Image Processing Basic\n",
    "   \n",
    "2.1.Spatial domain operation空间域运算. \n",
    "\n",
    "2.1.1.Point operations点运算,(描述原理,理解强度直方图,定义运算).\n",
    "\n",
    "2.1.1.1.原理\n",
    "    Contrast stretching对比拉伸:  \n",
    "    Intensity thresholding强度阈值:  \n",
    "        Automatic thresholding:  \n",
    "            Otsu. \n",
    "            Isodata. \n",
    "    Multilevel thresholding多级阈值:\n",
    "    Intensity Inversion强度反演:\n",
    "    Log transformation:\n",
    "    Power transformation:\n",
    "    Piecewise Linear transformoation分段线性变换:\n",
    "    Piecewise contrast stretching分段对比拉伸:\n",
    "    Gray-level slicing灰度切片:\n",
    "    Bit-plane slicing位平面切片:\n",
    "\n",
    "2.1.1.2.直方图. \n",
    "    Histogram processing直方图处理:\n",
    "        Histogram equalization直方图均衡. \n",
    "            Constrained受约束的:continuous/discrete. \n",
    "        Histogram specificaion(matching)直方图匹:continuous/discrete. \n",
    "    Arithmetic and logical operations算数逻辑运算:\n",
    "        加减,AND/OR\n",
    "    Averaging平均化:reduce noise in images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bee5b7d",
   "metadata": {},
   "source": [
    "# Week 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbeca0ff",
   "metadata": {},
   "source": [
    "2.1.2.Neighbourhood operations (spatial filtering空间滤波 on groups of pixels)邻域变换:\n",
    "\n",
    "2.1.2.1.Spatial filtering\n",
    "\n",
    "2.1.2.1.1.原理\n",
    "    使用输入图像中一个像素的小邻域内的灰度值来生成输出图像中该像素的新灰度值\n",
    "    根据对像素值应用的权重，它们可以抑制（滤除）或增强信息\n",
    "    权重矩阵称为滤波器filter或核kernel\n",
    "\n",
    "2.1.2.1.2.convolution卷积实现\n",
    "    输入图像𝑓(𝑥, 𝑦)和卷积核ℎ(𝑥, 𝑦)进行离散卷积discrete convolution计算\n",
    "    the kernel must be flipped核必须翻转\n",
    "    Fixing the border problem解决边框问题\n",
    "        Padding填充：将所有附加像素设置为常量（零）值：硬过渡会产生边框伪影（需要窗口处理）\n",
    "        Clamping夹持：无限重复所有边界像素值：边界行为更好但任意（无理论基础）\n",
    "        Wrapping包装：从对侧复制像素值：隐式用于（快速）傅里叶变换\n",
    "        Mirroring镜像：将像素值沿边界反射：平滑、对称、周期性、无边界伪影\n",
    "    linear, shift-invariant operation线性、平移不变的运算\n",
    "\n",
    "2.1.2.1.3.smoothing filter平滑滤波器(uniform filter均匀滤波器)\n",
    "    Calculates mean pixel value平均像素值 in a neighbourhood\n",
    "    used for image blurring and noise reduction图像模糊和降噪\n",
    "    Reduces fluctuations due to disturbances in image acquisition\n",
    "    Neighbourhood averaging also blurs the object edges物体边缘模糊 in the image\n",
    "    Can use weighted averaging加权平均 to give more importance to some pixels\n",
    "\n",
    "2.1.2.1.4.Gaussian filter高斯滤波器:平滑smoothing\n",
    "    the only filter that is both separable and circularly symmetric\n",
    "    optimal joint localization in spatial and frequency domain\n",
    "    Fourier transform of a Gaussian is also a Gaussian function\n",
    "    n-fold convolution of any low-pass filter converges to a Gaussian\n",
    "    infinitely smooth so it can be differentiated to any desired degree\n",
    "    scales naturally (sigma) and allows for consistent scale-space theory\n",
    "    如果必须保留小物体，高斯滤波效果最佳\n",
    "\n",
    "2.1.2.1.5.Median filter中值滤波器(nonlinear filter非线性滤波器)\n",
    "    order-statistics filter基于排序滤波器 (based on ordering and ranking pixel values)\n",
    "    Calculates the median pixel value中值像素值 in a neighbourhood 𝑁 with |𝑁| pixels\n",
    "    The median value 𝑚 of a set of ordered values is the middle value中间的值\n",
    "    most half the values in the set are < 𝑚 and the other half > 𝑚\n",
    "    取最小/最大值就是最小/最大滤波\n",
    "    Forces pixels with distinct intensities to be more like their neighbours使其更接近其邻居\n",
    "    It eliminates isolated intensity spikes (salt and pepper image noise)消除孤立的强度尖峰（椒盐图像噪声）\n",
    "    Neighbourhood is typically of size 𝒏 × 𝒏 pixels 通常是𝒏 × 𝒏像素 with 𝑛 = 3, 5, 7, \n",
    "    eliminates pixel clusters消除了像素簇 (light or dark) with area < 𝑛 2/2\n",
    "    如果必须去除小物体，中值滤波效果最佳\n",
    "\n",
    "2.1.2.1.6.Pooling池化\n",
    "    Combines filtering and downsampling in one operation\n",
    "    Examples include max / min / median / average pooling\n",
    "    Makes the image smaller and reduces computations\n",
    "    Popular in deep convolutional neural networks\n",
    "\n",
    "2.1.2.1.7.Derivative filters导数滤波器\n",
    "    Spatial derivatives respond to intensity changes (such as object edges)\n",
    "    In digital images they are approximated using finite differences\n",
    "    Different possible ways to take finite differences\n",
    "    Gaussian derivative filters高斯导数滤波器\n",
    "        Extension of Gaussian filter kernels to 2D and different spatial scales\n",
    "\n",
    "2.1.2.1.8.Prewitt and Sobel kernels普鲁伊特和索贝尔核\n",
    "    Differentiation in one dimension and smoothing in the other dimension\n",
    "\n",
    "2.1.2.1.9.Separable filter kernels可分离滤波器核\n",
    "    Allow for a much more computationally efficient implementation\n",
    "\n",
    "2.1.2.1.10.Laplacean filtering拉普拉斯滤波\n",
    "    Approximating the sum of second-order derivatives\n",
    "    Sharpening using the Laplacean使用拉普拉斯算子锐化\n",
    "\n",
    "2.1.2.1.11.Intensity gradient vector强度梯度向量\n",
    "    Gradient vector(2D)梯度向量\n",
    "        Points in the direction of steepest intensity increase\n",
    "        Is orthogonal to isophotes (lines of equal intensity)\n",
    "    Gradient magnitude(2D)梯度幅度\n",
    "        Represents the length of the gradient vector\n",
    "        Is the magnitude of the local intensity change\n",
    "        Edge detection边缘检测:\n",
    "            Edge detection with the Laplacean\n",
    "\n",
    "2.1.2.1.12.Selecting the right spatial scale选择合适的空间尺度\n",
    "    Computing image derivatives using Gaussian derivative kernels\n",
    "\n",
    "2.1.2.1.13.Differentiation in the Fourier domain傅里叶域中的微分\n",
    "    Differentiation suppresses low frequencies but blows up high frequencies (including noise)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6a87258",
   "metadata": {},
   "source": [
    "2.2.Transform domain operations (mainly in Fourier space)变换域操作（主要在傅里叶空间中）\n",
    "\n",
    "2.2.1.Frequency domain\n",
    "    High frequencies correspond to 1.rapidly changing intensities across pixel 高频对应于像素间快速变化的强度\n",
    "    Low frequency components correspond to 1.large-scale image structures 低频分量对应于图像的大规模结构\n",
    "                                           2.slowly varying intensities across pixels 像素间缓慢变化的强度\n",
    "    Noise typically corresponds to fluctuations in the highest frequencies 噪声通常对应于最高频率的波动\n",
    "    Frequency domain image processing via the Fourier transform 通过傅里叶变换进行频域图像处理\n",
    "        Fourier images are typically centred for visualisation and processing 傅里叶图像通常用于可视化和处理时会进行中心化\n",
    "\n",
    "\n",
    "2.2.2.Fourier transform (1D)/(2D)\n",
    "    Forward:\n",
    "    Inverse:\n",
    "        Uses complex valued sinusoids\n",
    "\n",
    "2.2.3.Discrete Fourier transform (DFT)离散傅里叶变换\n",
    "    Digital images are discrete 2D functions\n",
    "    The discrete Fourier transform and its inverse always exist\n",
    "    Forward:\n",
    "    Inverse:\n",
    "\n",
    "2.2.4.real-valued functions实值函数的傅里叶变换\n",
    "    A real-valued function always has a conjugate symmetric Fourier transform\n",
    "\n",
    "2.2.5.Procedure for frequency domain filtering\n",
    "    1. Multiply the input image 𝑓(𝑥, 𝑦) by (−1)^(x + 𝑦) to ensure centering 𝐹(𝑢, 𝑣)\n",
    "    2. Compute the transform 𝐹(𝑢, 𝑣) from image 𝑓(𝑥, 𝑦) using the 2D DFT\n",
    "    3. Multiply 𝐹(𝑢, 𝑣) by a centred filter 𝐻(𝑢, 𝑣) to obtain the result 𝐺(𝑢, 𝑣)\n",
    "    4. Compute the inverse 2D DFT of 𝐺(𝑢, 𝑣) to obtain the spatial result 𝑔(𝑥, 𝑦)\n",
    "    5. Take the real component of 𝑔(𝑥, 𝑦) (the imaginary component is zero)\n",
    "    6. Multiply the result by (−1)^(x + 𝑦) to remove the pattern introduced in step 1\n",
    "\n",
    "2.2.6.low-pass filtering低通滤波(blurred version of the original)\n",
    "\n",
    "2.2.7.notch filtering陷波滤波\n",
    "\n",
    "2.2.8.Exploiting the convolution theorem利用卷积定理\n",
    "    频域中的滤波在计算上可能更高效\n",
    "    在频域中设计滤波器可能更直观\n",
    "    低通滤波器：保留低频但衰减高频\n",
    "    高通滤波器：保留高频但衰减低频\n",
    "    带通滤波器：保留给定频段内的频率并衰减其余频率\n",
    "    进行逆变换以获得相应的空间滤波器\n",
    "\n",
    "2.2.9.Gaussian filter\n",
    "    low-pass:\n",
    "    high-pass:Approximation of an inverted Laplacean filter\n",
    "\n",
    "2.2.10.Multiresolution image processing 多分辨率图像处理\n",
    "    Small objects and fine details benefit from high resolution\n",
    "    Large objects and coarse structures can make do with lower resolution\n",
    "    If both are present at the same time, multiple resolutions may be useful\n",
    "    This requires computing image pyramids\n",
    "\n",
    "2.2.11.Creating image pyramids 创建图像金字塔\n",
    "    1.Compute an approximation of the input image by filtering and downsamplin 通过滤波和下采样来计算输入图像的近似值\n",
    "    2.Upsample the outputof step 1 and filter the result (interpolation)对步骤 1 的输出进行上采样并滤波（插值）\n",
    "    3. Compute the difference between the prediction of step 2 and the input to step 计算步骤 2 的预测值与步骤 1 的输入值之间的差异\n",
    "    To reconstruct the image:\n",
    "        1.对最低分辨率的近似图像进行Upsample上采样和filter滤波\n",
    "        2.Add the one-level higher prediction residual 添加一层更高的预测残差\n",
    "    Application: Approximation/Residual pyramid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1072c10a",
   "metadata": {},
   "source": [
    "# Week3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffedc118",
   "metadata": {},
   "source": [
    "3.Feature Representation\n",
    "\n",
    "3.1.image features\n",
    "vectors that are a compact representation of images\n",
    "why no pixels: change & highly redundant\n",
    "\n",
    "3.1.1.features properties\n",
    "Reproducibility (robustness)\n",
    "Saliency (descriptiveness) 不同图像中的相似突出点应具有相似的特征\n",
    "Saliency (descriptiveness)\n",
    "\n",
    "3.1.2.color features\n",
    "Invariant to image scaling, translation and rotation\n",
    "\n",
    "3.1.2.1.color histogram: Represent the global distribution of pixel colours in an image\n",
    "\n",
    "3.1.2.2.Color moments: Moments矩阵 based representation of colour distributions\n",
    "    一阶均值，二阶标准差，三阶偏度\n",
    "    only 9 elements (for RGB images)\n",
    "    Lower representation capability\n",
    "\n",
    "3.1.3.Texture features\n",
    "a powerful discriminating feature for identifying visual patterns\n",
    "\n",
    "3.1.3.1.Haralick Features(要考构建！！！！！！！！！)\n",
    "gives an array of statistical descriptors of image patterns to capture the spatial relationship between neighbouring pixels\n",
    "\n",
    "3.1.3.1.1.Step 1: Construct the gray-level co-occurrence matrix (GLCM)\n",
    "    representing the frequency of pixel intensity pairs occurring at a specific offset and direction\n",
    "    1.Given distance 𝑑 and orientation angle 𝑎\n",
    "    2.Compute co-occurrence count (or probability) 𝑝(%,') 𝑖), 𝑖\" of going from gray level 𝑖) to 𝑖\" at 𝑑 and 𝑎\n",
    "    3.Construct matrix 𝐏(%,') 𝑖), 𝑖\" with elements 𝑖), 𝑖\" being 𝑝(%,') 𝑖), 𝑖\"\n",
    "    4.If an image has 𝐿 distinct gray levels, the matrix size is 𝐿×𝐿\n",
    "    tips:1.For computational efficiency 𝐿 can be reduced by binning分箱\n",
    "         2.Different co-occurrence matrices can be constructed by using various combinations of distance 𝑑 and angular orientation 𝑎\n",
    "         3.On their own these co-occurrence matrices do not provide any measure of texture that can be easily used as texture descriptors\n",
    "         4.The information in the co-occurrence matrices needs to be further extracted as a set of feature values such as the Haralick descriptors\n",
    "\n",
    "3.1.3.1.2.Step 2: Compute the Haralick feature descriptors from the GLCM\n",
    "    that summarises texture information (how pixel intensities are spatially related)\n",
    "\n",
    "3.1.3.1.3.Application: in medical imaging studies due to their simplicity and interpretability\n",
    "\n",
    "3.1.3.2.Local binary patterns本地二进制模式\n",
    "    Describe the spatial structure of local image texture\n",
    "    1.Divide the image into cells of 𝑁×𝑁 pixels (for example 𝑁 = 16 or 32)\n",
    "    2.Compare each pixel in a given cell to each of its 8 neighbouring pixels\n",
    "    3.If the centre pixel value is greater than the neighbour value, write 0, otherwise write 1\n",
    "    4.This gives an 8-digit binary pattern per pixel, representing a value in the range 0…255\n",
    "    5.Count the number of times each 8-digit binary number occurs in the cell\n",
    "    6.This gives a 256-bin histogram (also known as the LBP feature vector)\n",
    "    7.Combine the histograms of all cells of the given image\n",
    "    8.This gives the image-level LBP feature descriptor\n",
    "\n",
    "    LBP can be multiresolution and rotation-invariant\n",
    "    Multiresolution多分辨率: vary the distance between the centre pixel and neighbouring pixels and vary the number of neighbouring pixels\n",
    "    Rotation-invariant旋转不变: vary the way of constructing the 8-digit binary number by performing bitwise shift to derive the smallest number\n",
    "        not all patterns have 8 shifted variant\n",
    "    Application: Texture classification\n",
    "\n",
    "3.1.3.3.Scale-Invariant Feature Transform尺度不变特征变换\n",
    "    describes texture in a localised region around a keypoint\n",
    "    descriptor is invariant to various transformations\n",
    "\n",
    "3.1.3.3.1.Step 1:SIFT Extrema Detectio极值检测: Detect maxima and minima in the scale space of the image\n",
    "3.1.3.3.2.Step 2:SIFT Keypoint Localization关键点定位: Improve and reduce the set of found keypoints\n",
    "    Use 3D quadratic fitting in scale-space to get subpixel optima\n",
    "    Reject low-contrast and edge points using Hessian analysis\n",
    "3.1.3.3.3.Step 3:SIFT Orientation Assignment方向分配: Estimate keypoint orientation using local gradient vectors\n",
    "    Make an orientation histogram of local gradient vectors\n",
    "    Find the dominant orientation from the main peak of the histogram\n",
    "    Create additional keypoint for second highest peak if >80%\n",
    "3.1.3.3.4.Step 4:SIFT Keypoint Descriptor关键点描述符:Represent each keypoint by a 128D feature vector\n",
    "    4 x 4 array of gradient histogram weighted by magnitude\n",
    "    8 bins in gradient orientation histogram\n",
    "    Total 8 x 4 x 4 array = 128 dimensions\n",
    "    Each keypoint represented by a 128D feature vector\n",
    "    Descriptor matching描述符匹配: Using the nearest neighbour distance ratio (NNDR)\n",
    "3.1.3.3.5.Application: Matching two partially overlapping images\n",
    "\n",
    "\n",
    "3.1.3.4.spatial transformation空间变换\n",
    "    Rigid transformations: Translation,Rotation\n",
    "    Nonrigid transformations: Scaling,Affine,Perspective\n",
    "\n",
    "3.1.3.5.Fitting and alignment安装和对齐\n",
    "    Least-squares (LS) fitting of corresponding keypoints 𝐱-, 𝐱-\n",
    "3.1.3.5.2.RANdom SAmple Consensus 随机抽样一致性(RANSAC) fitting\n",
    "    1. Sample (randomly) the number of points required to fit the model\n",
    "    2. Solve for the model parameters模型参数 using the samples\n",
    "    3. Score得分 by the fraction of inliers within a preset threshold of the model\n",
    "    Repeat 1-3 until the best model is found with high confidence\n",
    "\n",
    "3.1.3.6.Feature encoding 特征编码\n",
    "    Global encoding of local SIFT features本地 SIFT 特征的全局编码: Combine local SIFT keypoint descriptors of an image into one global vector\n",
    "3.1.3.6.2.Most popular method: Bag-of-Words (BoW)\n",
    "    Variable number of local image features\n",
    "    Encoded into a fixed-dimensional histogram\n",
    "    1.Step 1\n",
    "        Extract local SIFT keypoint descriptors from training images\n",
    "        Create the “vocabulary” from the set of SIFT keypoint descriptors\n",
    "        This vocabulary represents the categories of local descriptors\n",
    "        Main technique used to create the vocabulary is k-means clustering\n",
    "        One of the simplest and most popular unsupervised learning approaches\n",
    "        Performs automatic clustering (partitioning) of the training data into k categories\n",
    "    2.k-means clustering: k均值聚类\n",
    "        Initialize: k cluster centres (typically randomly)\n",
    "        Iterate: 1. Assign data (feature vectors) to the closest cluster (Euclidean distance)\n",
    "                 2. Update cluster centres as the mean of the data samples in each cluster\n",
    "        Terminate: When converged or the number of iterations reaches the maximum\n",
    "    2.Step 2\n",
    "        Cluster centres are the “visual words” in this “vocabulary” used to represent an image\n",
    "        Each local feature descriptor is assigned to one visual word with the smallest distance\n",
    "        Compute the number of local image feature descriptors assigned to each visual word\n",
    "        Concatenate the numbers into a vector which is the “BoW” representation of the image\n",
    "3.1.3.6.3: Application:SIFT-based texture classification\n",
    "    Build vocabulary Train classifier Classify image\n",
    "\n",
    "3.1.4: Shape features形状特征\n",
    "    Shape is an essential characteristic of material objects\n",
    "    Shape features are typically extracted after image segmentation\n",
    "    They can be used to identify and classify objects\n",
    "    Example: object recognition对象识别\n",
    "3.1.4.1: Challenges in defining shape features\n",
    "    Invariant to rigid transformations\n",
    "    Tolerant to non-rigid deformations\n",
    "    Unknown correspondence\n",
    "3.1.4.2: Basic shape features\n",
    "    Convexity versus concavity of an object\n",
    "    Convex hull of an object\n",
    "    Convex deficiency of an object\n",
    "    Simple geometrical shape descriptors:\n",
    "        Compactness inversely related Circularity\n",
    "        Elongation & Eccentricity\n",
    "3.1.4.3: Boundary descriptors边界描述符\n",
    "    Chain code descriptor链码描述符\n",
    "        Represents object shape by the relative positions of consecutive boundary points\n",
    "        Consists of a list of directions from a starting point\n",
    "        Provides a compact boundary representation\n",
    "    Local curvature descriptor局部曲率描述符\n",
    "        The curvature of an object is a local shape attribute\n",
    "        Convex (versus concave) parts have positive (versus negative) curvature\n",
    "    Two interpretations of local curvature局部曲率的两种解释\n",
    "        Geometrical & Physical\n",
    "    Global curvature descriptors全局曲率描述符\n",
    "        Total bending energy总弯曲能量 & Total absolute curvature总绝对曲率\n",
    "    Radial distance descriptor 径向距离描述符\n",
    "3.1.4.4:Application: Combining feature descriptors to classify objects 组合特征描述符以对对象进行分类\n",
    "\n",
    "3.1.4.5.Shape context形状上下文\n",
    "    Shape context is a point-wise local feature descriptor逐点局部特征描述符\n",
    "    Pick 𝑛 points 𝑝\" on the contour of a shape\n",
    "    For each point, create a radial coordinate system centred at this point and compute a histogram ℎ\" based on the relative coordinates of the other 𝑛 − 1 points\n",
    "    This is the shape context of 𝑝\"\n",
    "    Application: Shape matching\n",
    "        Step 1: Sample a list of points on shape edges For example from Canny edge detector\n",
    "        Step 2: Compute the shape context for each point\n",
    "        Step 3: Compute the cost matrix between two shapes 𝑃 and 𝑄\n",
    "        Step 4: Find the one-to-one matching minimising the total cost between point pairs\n",
    "        Step 5: Transform one shape to the other based on the one-to-one point matching\n",
    "        Step 6: Compute the shape distance\n",
    "\n",
    "3.1.4.6.Histogram of oriented gradients定向梯度直方图\n",
    "    Describes the distributions of gradient orientations in localized areas 描述局部区域中梯度方向的分布\n",
    "    Does not require initial segmentation 不需要初始分割\n",
    "    Step 1: Calculate the gradient vector梯度矢量 at each pixel\n",
    "        Gradient magnitude & Gradient orientation\n",
    "    Step 2: Construct the gradient histogram of all pixels in a cell\n",
    "        Divide orientations into 𝑁 bins (typically 𝑁 = 9 bins evenly splitting 180 degrees)\n",
    "        Assign the gradient magnitude of each pixel to the bin corresponding to its orientation\n",
    "    Step 3: Generate detection-window level HOG descriptor生成检测窗口级别的 HOG 描述符\n",
    "        Window Block Cell\n",
    "    Detection via sliding window on the image 通过图像上的滑动窗口进行检测\n",
    "        Compute the HOG descriptor for many example windows from a training dataset\n",
    "        Manually label each example window as either “person” or “background”\n",
    "        Train a classifier (such as SVM) from these example windows and labels\n",
    "        For each new (test) image predict the label of each window using this classifier\n",
    "    Application: Detecting humans in images\n",
    "                 Detecting and tracking humans in videos\n",
    "                 Fine-grained detection using deformable parts model 使用可变形零件模型进行细粒度检测"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5e2e464",
   "metadata": {},
   "source": [
    "# Week 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16362c5b",
   "metadata": {},
   "source": [
    "4.1Pattern recognition\n",
    "4.1.1.Supervised learning\n",
    "    Learning patterns in a set of data with available labels (ground truth)\n",
    "    4.1.1.1.Concepts\n",
    "        Objects are (identifiable) physical entities of which images are taken\n",
    "        Regions (ideally) correspond to objects after image segmentation\n",
    "        Classes are disjoint subsets of objects sharing common features\n",
    "        Labels are associated with objects and indicate to which class they belong\n",
    "        Classification is the process of assigning labels to objects based on features\n",
    "        Classifiers are algorithms/methods performing the classification task\n",
    "        Patterns are regularities in object features and are used by classifiers\n",
    "        Pattern Recognition Systems\n",
    "            Basic stages involved in the design of a classification system\n",
    "        Pre-processing aims to enhance images for further processing\n",
    "        Feature extraction reduces the data by measuring certain properties\n",
    "        Feature descriptors represent scalar properties of objects\n",
    "        Feature vectors capture all the properties measured from the data\n",
    "        Feature selection aims to keep only the most descriptive features\n",
    "        Models are (mathematical or statistical) descriptions of classes\n",
    "        Training samples are objects with known labels used to build models\n",
    "        Cost is the consequence of making an incorrect decision/assignment\n",
    "        Decision boundary is the demarcation between regions in feature space\n",
    "    4.1.1.2.Feature Vector Representation\n",
    "        Features represent knowledge about the object and go by other names such as predictors, descriptors,covariates, independent variables…\n",
    "    4.1.1.3.Feature Extraction\n",
    "        Characterise objects by measurements that are\n",
    "            Similar for objects in the same class/category\n",
    "            Different for objects in different classes\n",
    "        Use distinguishing features\n",
    "            Invariant to object position (translation)\n",
    "            Invariant to object orientation (rotation)\n",
    "            Invariant to … (depends on the application)\n",
    "            Good examples are shape, colour, texture\n",
    "        Design of features often based on prior experience or intuition\n",
    "        Select features that are robust to\n",
    "            Rigid transformations (translation and rotation)\n",
    "            Occlusions and other 3D-to-2D projective distortions\n",
    "            Non-rigid/articulated object deformations (e.g. fingers around a cup)\n",
    "            Variations in illumination and shadows\n",
    "        Feature selection is problem- and domain-dependent and requires domain knowledge\n",
    "        Classification techniques can help to make feature values less noise sensitive and to select valuable features out of a larger set\n",
    "    4.1.1.4.Pattern Recognition Models\n",
    "        Generative models\n",
    "            Model the “mechanism” by which the data was generated\n",
    "            Represent each class by a probabilistic “model” 𝑝 𝑥|𝑦 and 𝑝 𝑦\n",
    "            Obtain the joint probability of the data as 𝑝 𝑥, 𝑦 = 𝑝 𝑥|𝑦 𝑝 𝑦\n",
    "            Find the decision boundary implicitly via the most likely 𝑝 𝑦|𝑥\n",
    "            Applicable to unsupervised learning tasks (unlabelled data)\n",
    "        Discriminative models\n",
    "            Focus on explicit modelling of the decision boundary\n",
    "            Applicable to supervised learning tasks (labelled data)\n",
    "    4.1.1.5.Classification\n",
    "        Classifier performs object recognition by assigning a class label to an object, using the object description in the form of features\n",
    "        Perfect classification is often impossible, instead determine the probability for each possible class\n",
    "        Difficulties are caused by variability in feature values for objects in the same class versus objects in different classes\n",
    "        Variability may arise due to complexity but also due to noise\n",
    "        Noisy features and missing features are major issues\n",
    "        Not always possible to determine values of all features for an object\n",
    "    4.1.1.5.1.Binary Classification\n",
    "    4.1.1.5.2.Nearest Class Mean Classifier\n",
    "        Pros\n",
    "            Simple\n",
    "            Fast\n",
    "            Works well when classes are compact and far from each other\n",
    "        Cons\n",
    "            Poor results for complex classes (multimodal, non-spherical)\n",
    "            Cannot handle outliers and noisy data well\n",
    "            Cannot handle missing data\n",
    "    4.1.1.5.3.K-Nearest Neighbours Classifier\n",
    "        Pros\n",
    "            Very simple and intuitive\n",
    "            Easy to implement\n",
    "            No a priori assumptions\n",
    "            No training step\n",
    "            Decision surfaces are non-linear\n",
    "        Cons\n",
    "            Slow algorithm for big data sets\n",
    "            Needs homogeneous (similar nature) feature types and scales\n",
    "            Does not perform well when the number of variables grows (curse of dimensionality)\n",
    "            Finding the optimal K (number of neighbours) to use can be challenging\n",
    "        Applications\n",
    "            Automated MS-lesion segmentation by KNN\n",
    "    4.1.1.5.3.Bayesian Decision Theory\n",
    "        Risk:\n",
    "            If we only care about the classification accuracy (the prices of all types of fish are the same), then we can make the decision by maximizing the posterior probability\n",
    "            If the prices are not the same, we minimize the loss\n",
    "                Cost of an action 𝛼! based on our decision: 𝜆 𝛼! 𝑐!\n",
    "                The expected loss associated with action 𝛼! is:\n",
    "                    𝑅 𝛼! 𝑥 = ∑8 𝜆 𝛼! 𝑐8 𝑝(𝑐8|𝑥)\n",
    "                𝑅 𝛼! 𝑥 is also called conditional risk\n",
    "                An optimal Bayes decision strategy is to minimize the conditional risk\n",
    "        Pros\n",
    "            Simple and efficient\n",
    "            Considers uncertainties\n",
    "            Permits combining new information with current knowledge\n",
    "        Cons\n",
    "            Struggles with complex data relationships\n",
    "            Choice of priors can be subjective\n",
    "    4.1.1.6.Decision Trees\n",
    "        Most pattern recognition methods address problems where feature vectors are real-valued and there exists some notion of a metric\n",
    "        Some classification problems involve nominal data, with discrete descriptors and without a natural notion of similarity or ordering\n",
    "            Example: {high, medium, low}, {red, green, blue}\n",
    "            Nominal data are also called as categorical data\n",
    "        Nominal data can be classified using rule-based method\n",
    "        Continuous values can also be handled with rule-based method\n",
    "        Pros\n",
    "            Easy to interpret\n",
    "            Can handle both numerical and categorical data\n",
    "            Robust to outliers and missing values\n",
    "            Gives information on importance of features (feature selection)\n",
    "        Cons\n",
    "            Tends to overfit\n",
    "            Only axis-aligned splits\n",
    "            Greedy algorithm (may not find the best tree)\n",
    "\n",
    "\n",
    "\n",
    "    4.1.8.Support Vector Machines (SVMs)\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "4.1.2.Unsupervised learning\n",
    "Finding patterns in a set of data without any labels available\n",
    "4.1.3.Semi-supervised learning\n",
    "Using a combination of labelled and unlabelled data to learn patterns\n",
    "4.1.4.Weakly supervised learning\n",
    "Using noisy / limited / imprecise supervision signals in learning of patterns"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
